{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can read an overview of this Numerical Linear Algebra course in [this blog post](http://www.fast.ai/2017/07/17/num-lin-alg/).  The course was originally taught in the [University of San Francisco MS in Analytics](https://www.usfca.edu/arts-sciences/graduate-programs/analytics) graduate program.  Course lecture videos are [available on YouTube](https://www.youtube.com/playlist?list=PLtmWHNX-gukIc92m1K0P6bIOnZb-mg0hY) (note that the notebook numbers and video numbers do not line up, since some notebooks took longer than 1 video to cover).\n",
    "\n",
    "You can ask questions about the course on [our fast.ai forums](http://forums.fast.ai/c/lin-alg)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. How to Implement Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous lesson, we calculated the least squares linear regression for a diabetes dataset, using scikit learn's implementation.  Today, we will look at how we could write our own implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets, linear_model, metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "import math, scipy, numpy as np\n",
    "from scipy import linalg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(precision=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = datasets.load_diabetes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names=['age', 'sex', 'bmi', 'bp', 's1', 's2', 's3', 's4', 's5', 's6']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn,test,y_trn,y_test = train_test_split(data.data, data.target, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((353, 10), (89, 10))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trn.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def regr_metrics(act, pred):\n",
    "    return (math.sqrt(metrics.mean_squared_error(act, pred)), \n",
    "     metrics.mean_absolute_error(act, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How did sklearn do it?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How is sklearn doing this?  By checking [the source code](https://github.com/scikit-learn/scikit-learn/blob/14031f6/sklearn/linear_model/base.py#L417), you can see that in the dense case, it calls [scipy.linalg.lstqr](https://github.com/scipy/scipy/blob/v0.19.0/scipy/linalg/basic.py#L892-L1058), which is calling a LAPACK method:\n",
    "\n",
    "        Options are ``'gelsd'``, ``'gelsy'``, ``'gelss'``. Default\n",
    "        (``'gelsd'``) is a good choice.  However, ``'gelsy'`` can be slightly\n",
    "        faster on many problems.  ``'gelss'`` was used historically.  It is\n",
    "        generally slow but uses less memory.\n",
    "\n",
    "- [gelsd](https://software.intel.com/sites/products/documentation/doclib/mkl_sa/11/mkl_lapack_examples/_gelsd.htm): uses SVD and a divide-and-conquer method\n",
    "- [gelsy](https://software.intel.com/en-us/node/521113): uses QR factorization\n",
    "- [gelss](https://software.intel.com/en-us/node/521114): uses SVD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### Scipy Sparse Least Squares"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We will not get into too much detail about the sparse version of least squares.  Here is a bit of info if you are interested: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "[Scipy sparse lsqr](https://docs.scipy.org/doc/scipy-0.14.0/reference/generated/scipy.sparse.linalg.lsqr.html#id1) uses an iterative method called [Golub and Kahan bidiagonalization](https://web.stanford.edu/class/cme324/paige-saunders2.pdf)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "from [scipy sparse lsqr source code](https://github.com/scipy/scipy/blob/v0.14.0/scipy/sparse/linalg/isolve/lsqr.py#L96):\n",
    "  Preconditioning is another way to reduce the number of iterations. If it is possible to solve a related system ``M*x = b`` efficiently, where M approximates A in some helpful way (e.g. M - A has low rank or its elements are small relative to those of A), LSQR may converge more rapidly on the system ``A*M(inverse)*z = b``, after which x can be recovered by solving M\\*x = z.\n",
    "  \n",
    "If A is symmetric, LSQR should not be used! Alternatives are the symmetric conjugate-gradient method (cg) and/or SYMMLQ.  SYMMLQ is an implementation of symmetric cg that applies to any symmetric A and will converge more rapidly than LSQR.  If A is positive definite, there are other implementations of symmetric cg that require slightly less work per iteration than SYMMLQ (but will take the same number of iterations)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### linalg.lstqr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sklearn implementation handled adding a constant term (since the y-intercept is presumably not 0 for the line we are learning) for us.  We will need to do that by hand now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_int = np.c_[trn, np.ones(trn.shape[0])]\n",
    "test_int = np.c_[test, np.ones(test.shape[0])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since `linalg.lstsq` lets us specify which LAPACK routine we want to use, lets try them all and do some timing comparisons:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130 µs ± 9.99 µs per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit coef, _,_,_ = linalg.lstsq(trn_int, y_trn, lapack_driver=\"gelsd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76.1 µs ± 440 ns per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit coef, _,_,_ = linalg.lstsq(trn_int, y_trn, lapack_driver=\"gelsy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "139 µs ± 9.1 µs per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit coef, _,_,_ = linalg.lstsq(trn_int, y_trn, lapack_driver=\"gelss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that we want to find $\\hat{x}$ that minimizes: \n",
    "$$ \\big\\vert\\big\\vert Ax - b \\big\\vert\\big\\vert_2$$\n",
    "\n",
    "Another way to think about this is that we are interested in where vector $b$ is closest to the subspace spanned by $A$ (called the *range of* $A$).  This is the projection of $b$ onto $A$.  Since $b - A\\hat{x}$ must be perpendicular to the subspace spanned by $A$, we see that\n",
    "\n",
    "$$A^T (b - A\\hat{x}) = 0 $$\n",
    "\n",
    "(we are using $A^T$ because we want to multiply each column of $A$ by $b - A\\hat{x}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This leads us to the *normal equations*:\n",
    "$$ x = (A^TA)^{-1}A^T b $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ls_naive(A, b):\n",
    "     return np.linalg.inv(A.T @ A) @ A.T @ b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93.3 µs ± 19 µs per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit coeffs_naive = ls_naive(trn_int, y_trn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55.980450808470835, 45.79612140213504)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coeffs_naive = ls_naive(trn_int, y_trn)\n",
    "regr_metrics(y_test, test_int @ coeffs_naive)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normal Equations (Cholesky)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normal equations:\n",
    "$$ A^TA x = A^T b $$\n",
    "\n",
    "If $A$ has full rank, the pseudo-inverse $(A^TA)^{-1}A^T$ is a **square, hermitian positive definite** matrix.  The standard way of solving such a system is *Cholesky Factorization*, which finds upper-triangular R s.t. $A^TA = R^TR$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following steps are based on Algorithm 11.1 from Trefethen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = trn_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = y_trn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "AtA = A.T @ A\n",
    "Atb = A.T @ b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Warning:** Numpy and Scipy default to different upper/lower for Cholesky"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "R = scipy.linalg.cholesky(AtA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.9017,  0.1253,  0.1609,  0.3183,  0.2147,  0.1754, -0.0917,\n",
       "         0.1837,  0.2724,  0.3011, -0.4991],\n",
       "       [ 0.    ,  0.8825,  0.0446,  0.1884, -0.0034,  0.0984, -0.3253,\n",
       "         0.2634,  0.091 ,  0.1284, -0.7197],\n",
       "       [ 0.    ,  0.    ,  0.8658,  0.2492,  0.1789,  0.2051, -0.3251,\n",
       "         0.3382,  0.3519,  0.2387, -0.3352],\n",
       "       [ 0.    ,  0.    ,  0.    ,  0.7632,  0.1293,  0.0586,  0.0278,\n",
       "         0.0365,  0.1692,  0.1342, -0.0044],\n",
       "       [ 0.    ,  0.    ,  0.    ,  0.    ,  0.833 ,  0.7507,  0.1083,\n",
       "         0.3995,  0.343 ,  0.1597,  0.4123],\n",
       "       [ 0.    ,  0.    ,  0.    ,  0.    ,  0.    ,  0.3827, -0.4228,\n",
       "         0.2773, -0.321 , -0.0184, -0.4645],\n",
       "       [ 0.    ,  0.    ,  0.    ,  0.    ,  0.    ,  0.    ,  0.6486,\n",
       "        -0.4947, -0.5202, -0.1753,  0.6192],\n",
       "       [ 0.    ,  0.    ,  0.    ,  0.    ,  0.    ,  0.    ,  0.    ,\n",
       "         0.2972, -0.0092,  0.0593,  0.3315],\n",
       "       [ 0.    ,  0.    ,  0.    ,  0.    ,  0.    ,  0.    ,  0.    ,\n",
       "         0.    ,  0.2745,  0.0743, -0.2547],\n",
       "       [ 0.    ,  0.    ,  0.    ,  0.    ,  0.    ,  0.    ,  0.    ,\n",
       "         0.    ,  0.    ,  0.7398,  0.2591],\n",
       "       [ 0.    ,  0.    ,  0.    ,  0.    ,  0.    ,  0.    ,  0.    ,\n",
       "         0.    ,  0.    ,  0.    , 18.7379]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.set_printoptions(suppress=True, precision=4)\n",
    "R"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "check our factorization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.533174660942573e-16"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(AtA - R.T @ R)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ A^T A x = A^T b $$\n",
    "$$ R^T R x = A^T b $$\n",
    "$$ R^T w = A^T b $$\n",
    "$$ R x = w $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = scipy.linalg.solve_triangular(R, Atb, lower=False, trans='T')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's always good to check that our result is what we expect it to be: (in case we entered the wrong params, the function didn't return what we thought, or sometimes the docs are even outdated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.278399695011219e-12"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(R.T @ w - Atb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "coeffs_chol = scipy.linalg.solve_triangular(R, w, lower=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.31335954426011e-13"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(R @ coeffs_chol - w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ls_chol(A, b):\n",
    "    R = scipy.linalg.cholesky(A.T @ A)\n",
    "    w = scipy.linalg.solve_triangular(R, A.T @ b, trans='T')\n",
    "    return scipy.linalg.solve_triangular(R, w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64.8 µs ± 2.17 µs per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit coeffs_chol = ls_chol(trn_int, y_trn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55.980450808470955, 45.79612140213507)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coeffs_chol = ls_chol(trn_int, y_trn)\n",
    "regr_metrics(y_test, test_int @ coeffs_chol)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QR Factorization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ A x = b $$\n",
    "$$ A = Q R $$\n",
    "$$ Q R x = b $$\n",
    "\n",
    "$$ R x = Q^T b $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ls_qr(A,b):\n",
    "    Q, R = scipy.linalg.qr(A, mode='economic')\n",
    "    return scipy.linalg.solve_triangular(R, Q.T @ b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99.6 µs ± 1.54 µs per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit coeffs_qr = ls_qr(trn_int, y_trn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55.980450808470955, 45.79612140213508)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coeffs_qr = ls_qr(trn_int, y_trn)\n",
    "regr_metrics(y_test, test_int @ coeffs_qr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ A x = b $$\n",
    "\n",
    "$$ A = U \\Sigma V $$\n",
    "\n",
    "$$ \\Sigma V x = U^T b $$\n",
    "\n",
    "$$ \\Sigma w = U^T b $$\n",
    "\n",
    "$$ x = V^T w $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVD gives the pseudo-inverse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ls_svd(A,b):\n",
    "    m, n = A.shape\n",
    "    U, sigma, Vh = scipy.linalg.svd(A, full_matrices=False, lapack_driver='gesdd')\n",
    "    w = (U.T @ b)/ sigma\n",
    "    return Vh.T @ w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "127 µs ± 4.73 µs per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit coeffs_svd = ls_svd(trn_int, y_trn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123 µs ± 4.28 µs per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit coeffs_svd = ls_svd(trn_int, y_trn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55.98045080847082, 45.79612140213493)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coeffs_svd = ls_svd(trn_int, y_trn)\n",
    "regr_metrics(y_test, test_int @ coeffs_svd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Sketching Technique for Least Squares Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Linear Sketching](http://researcher.watson.ibm.com/researcher/files/us-dpwoodru/journal.pdf) (Woodruff)\n",
    "\n",
    "1. Sample a r x n random matrix S, r << n\n",
    "2. Compute S A and S b\n",
    "3. Find exact solution x to regression SA x = Sb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Timing Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-4486c3e73fd8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtimeit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "import timeit\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scipylstq(A, b):\n",
    "    return scipy.linalg.lstsq(A,b)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_names = ['Normal Eqns- Naive',\n",
    "             'Normal Eqns- Cholesky', \n",
    "             'QR Factorization', \n",
    "             'SVD', \n",
    "             'Scipy lstsq']\n",
    "\n",
    "name2func = {'Normal Eqns- Naive': 'ls_naive', \n",
    "             'Normal Eqns- Cholesky': 'ls_chol', \n",
    "             'QR Factorization': 'ls_qr',\n",
    "             'SVD': 'ls_svd',\n",
    "             'Scipy lstsq': 'scipylstq'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_array = np.array([100, 1000, 10000])\n",
    "n_array = np.array([20, 100, 1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = pd.MultiIndex.from_product([m_array, n_array], names=['# rows', '# cols'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.float_format = '{:,.6f}'.format\n",
    "df = pd.DataFrame(index=row_names, columns=index)\n",
    "df_error = pd.DataFrame(index=row_names, columns=index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%prun\n",
    "for m in m_array:\n",
    "    for n in n_array:\n",
    "        if m >= n:        \n",
    "            x = np.random.uniform(-10,10,n)\n",
    "            A = np.random.uniform(-40,40,[m,n])   # removed np.asfortranarray\n",
    "            b = np.matmul(A, x) + np.random.normal(0,2,m)\n",
    "            for name in row_names:\n",
    "                fcn = name2func[name]\n",
    "                t = timeit.timeit(fcn + '(A,b)', number=5, globals=globals())\n",
    "                df.set_value(name, (m,n), t)\n",
    "                coeffs = locals()[fcn](A, b)\n",
    "                reg_met = regr_metrics(b, A @ coeffs)\n",
    "                df_error.set_value(name, (m,n), reg_met[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "store = pd.HDFStore('least_squares_results.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "store['df'] = df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I used the magick %prun to profile my code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternative: least absolute deviation (L1 regression)\n",
    "- Less sensitive to outliers than least squares.\n",
    "- No closed form solution, but can solve with linear programming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Conditioning & stability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Condition Number"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "*Condition number* is a measure of how small changes to the input cause the output to change.\n",
    "\n",
    "**Question**: Why do we care about behavior with small changes to the input in numerical linear algebra?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The *relative condition number* is defined by\n",
    "\n",
    "$$ \\kappa = \\sup_{\\delta x} \\frac{\\|\\delta f\\|}{\\| f(x) \\|}\\bigg/ \\frac{\\| \\delta x \\|}{\\| x \\|} $$\n",
    "  \n",
    "where $\\delta x$ is infinitesimal\n",
    "\n",
    "According to Trefethen (pg. 91), a problem is *well-conditioned* if $\\kappa$ is small (e.g. $1$, $10$, $10^2$) and *ill-conditioned* if $\\kappa$ is large (e.g. $10^6$, $10^{16}$)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**Conditioning**: perturbation behavior of a mathematical problem (e.g. least squares)\n",
    "\n",
    "**Stability**: perturbation behavior of an algorithm used to solve that problem on a computer (e.g. least squares algorithms, householder, back substitution, gaussian elimination)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Conditioning example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The problem of computing eigenvalues of a non-symmetric matrix is often ill-conditioned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "A = [[1, 1000], [0, 1]]\n",
    "B = [[1, 1000], [0.001, 1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "wA, vrA = scipy.linalg.eig(A)\n",
    "wB, vrB = scipy.linalg.eig(B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "wA, wB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Condition Number of a Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The product $\\| A\\| \\|A^{-1} \\|$ comes up so often it has its own name: the *condition number* of $A$.  Note that normally we talk about the conditioning of problems, not matrices.\n",
    "\n",
    "The *condition number* of $A$ relates to:\n",
    "- computing $b$ given $A$ and $x$ in $Ax = b$\n",
    "- computing $x$ given $A$ and $b$ in $Ax = b$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loose ends from last time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full vs Reduced Factorizations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SVD**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Diagrams from Trefethen:\n",
    "\n",
    "<img src=\"images/full_svd.JPG\" alt=\"\" style=\"width: 80%\"/>\n",
    "\n",
    "<img src=\"images/reduced_svd.JPG\" alt=\"\" style=\"width: 70%\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**QR Factorization exists for ALL matrices**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just like with SVD, there are full and reduced versions of the QR factorization.\n",
    "\n",
    "<img src=\"images/full_qr.JPG\" alt=\"\" style=\"width: 70%\"/>\n",
    "\n",
    "<img src=\"images/reduced_qr.JPG\" alt=\"\" style=\"width: 70%\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matrix Inversion is Unstable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.linalg import hilbert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 14\n",
    "A = hilbert(n)\n",
    "x = np.random.uniform(-10,10,n)\n",
    "b = A @ x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_inv = np.linalg.inv(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.linalg.norm(np.eye(n) - A @ A_inv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.linalg.cond(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A @ A_inv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_names = ['Normal Eqns- Naive',\n",
    "             'QR Factorization', \n",
    "             'SVD', \n",
    "             'Scipy lstsq']\n",
    "\n",
    "name2func = {'Normal Eqns- Naive': 'ls_naive', \n",
    "             'QR Factorization': 'ls_qr',\n",
    "             'SVD': 'ls_svd',\n",
    "             'Scipy lstsq': 'scipylstq'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.float_format = '{:,.9f}'.format\n",
    "df = pd.DataFrame(index=row_names, columns=['Time', 'Error'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name in row_names:\n",
    "    fcn = name2func[name]\n",
    "    t = timeit.timeit(fcn + '(A,b)', number=5, globals=globals())\n",
    "    coeffs = locals()[fcn](A, b)\n",
    "    df.set_value(name, 'Time', t)\n",
    "    df.set_value(name, 'Error', regr_metrics(b, A @ coeffs)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVD is best here!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DO NOT RERUN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Another reason not to take inverse**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even if $A$ is incredibly sparse, $A^{-1}$ is generally dense.  For large matrices, $A^{-1}$ could be so dense as to not fit in memory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Runtime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matrix Inversion: $2n^3$\n",
    "\n",
    "Matrix Multiplication: $n^3$\n",
    "\n",
    "Cholesky: $\\frac{1}{3}n^3$\n",
    "\n",
    "QR, Gram Schmidt: $2mn^2$, $m\\geq n$ (chapter 8 of Trefethen)\n",
    "\n",
    "QR, Householder: $2mn^2 - \\frac{2}{3}n^3$ (chapter 10 of Trefethen)\n",
    "\n",
    "Solving a triangular system: $n^2$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Why Cholesky Factorization is Fast:**\n",
    "\n",
    "<img src=\"images/cholesky_factorization_speed.png\" alt=\"\" style=\"width: 100%\"/>\n",
    "(source: [Stanford Convex Optimization: Numerical Linear Algebra Background Slides](http://stanford.edu/class/ee364a/lectures/num-lin-alg.pdf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### A Case Where QR is the Best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "m=100\n",
    "n=15\n",
    "t=np.linspace(0, 1, m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Vandermonde matrix\n",
    "A=np.stack([t**i for i in range(n)], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "b=np.exp(np.sin(4*t))\n",
    "\n",
    "# This will turn out to normalize the solution to be 1\n",
    "b /= 2006.787453080206"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plt.plot(t, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Check that we get 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "1 - ls_qr(A, b)[14]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Bad condition number:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "kappa = np.linalg.cond(A); kappa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "row_names = ['Normal Eqns- Naive',\n",
    "             'QR Factorization', \n",
    "             'SVD', \n",
    "             'Scipy lstsq']\n",
    "\n",
    "name2func = {'Normal Eqns- Naive': 'ls_naive', \n",
    "             'QR Factorization': 'ls_qr',\n",
    "             'SVD': 'ls_svd',\n",
    "             'Scipy lstsq': 'scipylstq'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pd.options.display.float_format = '{:,.9f}'.format\n",
    "df = pd.DataFrame(index=row_names, columns=['Time', 'Error'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for name in row_names:\n",
    "    fcn = name2func[name]\n",
    "    t = timeit.timeit(fcn + '(A,b)', number=5, globals=globals())\n",
    "    coeffs = locals()[fcn](A, b)\n",
    "    df.set_value(name, 'Time', t)\n",
    "    df.set_value(name, 'Error', np.abs(1 - coeffs[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "\n",
    "The solution for least squares via the normal equations is unstable in general, although stable for problems with small condition numbers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Low-rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "m = 100\n",
    "n = 10\n",
    "x = np.random.uniform(-10,10,n)\n",
    "A2 = np.random.uniform(-40,40, [m, int(n/2)])   # removed np.asfortranarray\n",
    "A = np.hstack([A2, A2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "A.shape, A2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "b = A @ x + np.random.normal(0,1,m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "row_names = ['Normal Eqns- Naive',\n",
    "             'QR Factorization', \n",
    "             'SVD', \n",
    "             'Scipy lstsq']\n",
    "\n",
    "name2func = {'Normal Eqns- Naive': 'ls_naive', \n",
    "             'QR Factorization': 'ls_qr',\n",
    "             'SVD': 'ls_svd',\n",
    "             'Scipy lstsq': 'scipylstq'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pd.options.display.float_format = '{:,.9f}'.format\n",
    "df = pd.DataFrame(index=row_names, columns=['Time', 'Error'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for name in row_names:\n",
    "    fcn = name2func[name]\n",
    "    t = timeit.timeit(fcn + '(A,b)', number=5, globals=globals())\n",
    "    coeffs = locals()[fcn](A, b)\n",
    "    df.set_value(name, 'Time', t)\n",
    "    df.set_value(name, 'Error', regr_metrics(b, A @ coeffs)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our results from above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From Trefethen (page 84):\n",
    "\n",
    "Normal equations/Cholesky is fastest when it works.  Cholesky can only be used on symmetric, positive definite matrices.  Also, normal equations/Cholesky is unstable for matrices with high condition numbers or with low-rank.\n",
    "\n",
    "Linear regression via QR has been recommended by numerical analysts as the standard method for years.  It is natural, elegant, and good for \"daily use\"."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jupyter-pythonEnvForProj2MN-linearRegressionEnv",
   "language": "python",
   "name": "jupyter-pythonenvforproj2mn-linearregressionenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
